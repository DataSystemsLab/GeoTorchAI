{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dee2483",
   "metadata": {},
   "source": [
    "# This Example shows the Prediction of Bike Flow in the NYC City using the deep learning model ST-ResNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f1cee6",
   "metadata": {},
   "source": [
    "Find the details of the ST-ResNet model in the <a href=\"https://dl.acm.org/doi/10.5555/3298239.3298479\">corresponding paper</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b8ec05",
   "metadata": {},
   "source": [
    "Details of the dataset can be found <a href=\"https://github.com/FIBLAB/DeepSTN\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6762142",
   "metadata": {},
   "source": [
    "### Import Modules and Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f799943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "from geotorchai.models.grid import STResNet\n",
    "from geotorchai.datasets.grid import BikeNYCDeepSTN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29ba9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define parameters\n",
    "len_closeness = 3\n",
    "len_period = 4\n",
    "len_trend = 4\n",
    "nb_residual_unit = 4\n",
    "map_height, map_width = 21, 12\n",
    "nb_flow = 2\n",
    "nb_area = 81\n",
    "T = 24\n",
    "\n",
    "epoch_nums = 10\n",
    "learning_rate = 0.0002\n",
    "batch_size = 32\n",
    "validation_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "params = {'batch_size': batch_size, 'shuffle': False}\n",
    "\n",
    "## make sure that PATH_TO_DATASET exists in the running directory\n",
    "PATH_TO_DATASET = \"data/deepstn\"\n",
    "MODEL_SAVE_DIR = \"model-stresnet\"\n",
    "MODEL_SAVE_PATH = MODEL_SAVE_DIR + \"/stresnet.pth\"\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed609405",
   "metadata": {},
   "source": [
    "### Loading Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc3cdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloading started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 17708640/17708640 [00:00<00:00, 31568249.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloading finished\n",
      "File downloading started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 18224/18224 [00:00<00:00, 7864697.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloading finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Load training and test dataset\n",
    "full_dataset = BikeNYCDeepSTN(root = PATH_TO_DATASET, download = True)\n",
    "\n",
    "## get the min-max-difference of normalized data for future use in calculating actual losses\n",
    "min_max_diff = full_dataset.get_min_max_difference()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a06ab1",
   "metadata": {},
   "source": [
    "### Split Train Dataset into Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09fd64b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize training and validation indices to split the dataset\n",
    "dataset_size = len(full_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "val_split = int(np.floor((1 - (validation_ratio + test_ratio)) * dataset_size))\n",
    "test_split = int(np.floor((1 - test_ratio) * dataset_size))\n",
    "train_indices, val_indices, test_indices = indices[:val_split], indices[val_split:test_split], indices[test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f03105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define training and validation data sampler\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "## Define training and validation data loader\n",
    "train_loader = DataLoader(full_dataset, **params, sampler=train_sampler)\n",
    "val_loader = DataLoader(full_dataset, **params, sampler=valid_sampler)\n",
    "test_loader = DataLoader(full_dataset, **params, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c026f70",
   "metadata": {},
   "source": [
    "### Initialize Model and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b021059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## set device to CPU or GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "## Define Model\n",
    "model = STResNet((len_closeness, nb_flow, map_height, map_width),\n",
    "                (len_period, nb_flow, map_height, map_width),\n",
    "                (len_trend, nb_flow , map_height, map_width),\n",
    "                external_dim = None, nb_residual_unit = nb_residual_unit)\n",
    "## Define hyper-parameters\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.to(device)\n",
    "loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c22d3",
   "metadata": {},
   "source": [
    "### Method for Returning Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3745a178",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Before starting training, define a method to calculate validation loss\n",
    "def get_validation_loss(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    mean_loss = []\n",
    "    for i, sample in enumerate(data_loader):\n",
    "        X_c = sample[\"x_closeness\"].type(torch.FloatTensor).to(device)\n",
    "        X_p = sample[\"x_period\"].type(torch.FloatTensor).to(device)\n",
    "        X_t = sample[\"x_trend\"].type(torch.FloatTensor).to(device)\n",
    "        Y_batch = sample[\"y_data\"].type(torch.FloatTensor).to(device)\n",
    "\n",
    "        outputs = model(X_c, X_p, X_t)\n",
    "        mse= criterion(outputs, Y_batch).item()\n",
    "        mean_loss.append(mse)\n",
    "\n",
    "    mean_loss = np.mean(mean_loss)\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732ea6c3",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "897e8df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.0066\n",
      "Mean validation loss: 0.008179346293521425\n",
      "Best model saved!\n",
      "Epoch [2/10], Training Loss: 0.0019\n",
      "Mean validation loss: 0.003460483121064802\n",
      "Best model saved!\n",
      "Epoch [3/10], Training Loss: 0.0018\n",
      "Mean validation loss: 0.0025046314112842083\n",
      "Best model saved!\n",
      "Epoch [4/10], Training Loss: 0.0020\n",
      "Mean validation loss: 0.0020039992523379624\n",
      "Best model saved!\n",
      "Epoch [5/10], Training Loss: 0.0014\n",
      "Mean validation loss: 0.0017165297467727214\n",
      "Best model saved!\n",
      "Epoch [6/10], Training Loss: 0.0010\n",
      "Mean validation loss: 0.0015735180738071601\n",
      "Best model saved!\n",
      "Epoch [7/10], Training Loss: 0.0008\n",
      "Mean validation loss: 0.0014622912761600066\n",
      "Best model saved!\n",
      "Epoch [8/10], Training Loss: 0.0006\n",
      "Mean validation loss: 0.00130579936861371\n",
      "Best model saved!\n",
      "Epoch [9/10], Training Loss: 0.0007\n",
      "Mean validation loss: 0.001220505762224396\n",
      "Best model saved!\n",
      "Epoch [10/10], Training Loss: 0.0010\n",
      "Mean validation loss: 0.0011776623384018119\n",
      "Best model saved!\n"
     ]
    }
   ],
   "source": [
    "## Perform training and validation\n",
    "min_val_loss = None\n",
    "for e in range(epoch_nums):\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        X_c = sample[\"x_closeness\"].type(torch.FloatTensor).to(device)\n",
    "        X_p = sample[\"x_period\"].type(torch.FloatTensor).to(device)\n",
    "        X_t = sample[\"x_trend\"].type(torch.FloatTensor).to(device)\n",
    "        Y_batch = sample[\"y_data\"].type(torch.FloatTensor).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X_c, X_p, X_t)\n",
    "        loss = loss_fn(outputs, Y_batch)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Training Loss: {:.4f}'.format(e + 1, epoch_nums, loss.item()))\n",
    "\n",
    "    ## Perform model validation after finishing each epoch training\n",
    "    val_loss = get_validation_loss(model, val_loader, loss_fn, device)\n",
    "    print('Mean validation loss:', val_loss)\n",
    "\n",
    "    if min_val_loss == None or val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print('Best model saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c4499f",
   "metadata": {},
   "source": [
    "### Define a Method to Return MSE, MAE, RMSE Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa2cbb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Before testing, Define a method to calculate three types of loss: MSE, MAE, RMSE\n",
    "def compute_errors(preds, y_true):\n",
    "    pred_mean = preds[:, 0:2]\n",
    "    diff = y_true - pred_mean\n",
    "\n",
    "    mse = np.mean(diff ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(diff))\n",
    "\n",
    "    return mse, mae, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6d3503",
   "metadata": {},
   "source": [
    "### Evaluate on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4665a4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mse: 0.001049 mae: 0.013647 rmse (norm): 0.032330, mae (real): 5.028948, rmse (real): 11.913621\n"
     ]
    }
   ],
   "source": [
    "## Perform testing on the best model with test dataset\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=lambda storage, loc: storage))\n",
    "\n",
    "rmse_list=[]\n",
    "mse_list=[]\n",
    "mae_list=[]\n",
    "for i, sample in enumerate(test_loader):\n",
    "    X_c = sample[\"x_closeness\"].type(torch.FloatTensor).to(device)\n",
    "    X_p = sample[\"x_period\"].type(torch.FloatTensor).to(device)\n",
    "    X_t = sample[\"x_trend\"].type(torch.FloatTensor).to(device)\n",
    "    Y_batch = sample[\"y_data\"].type(torch.FloatTensor).to(device)\n",
    "\n",
    "    outputs = model(X_c, X_p, X_t)\n",
    "    mse, mae, rmse = compute_errors(outputs.cpu().data.numpy(), Y_batch.cpu().data.numpy())\n",
    "\n",
    "    rmse_list.append(rmse)\n",
    "    mse_list.append(mse)\n",
    "    mae_list.append(mae)\n",
    "    \n",
    "rmse = np.mean(rmse_list)\n",
    "mse = np.mean(mse_list)\n",
    "mae = np.mean(mae_list)\n",
    "\n",
    "print('Test mse: %.6f mae: %.6f rmse (norm): %.6f, mae (real): %.6f, rmse (real): %.6f' % (mse, mae, rmse, mae * min_max_diff/2, rmse*min_max_diff/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed3fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
