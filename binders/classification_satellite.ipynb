{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b83b01",
   "metadata": {},
   "source": [
    "# This Example shows how to classify EuroSAT satellite images using the deep learning model DeepSAT-V2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9369c5c",
   "metadata": {},
   "source": [
    "Find the details of the DeepSAT-V2 model in the <a href=\"https://arxiv.org/abs/1911.07747\">corresponding paper</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb2da4",
   "metadata": {},
   "source": [
    "Find the details of the dataset <a href=\"https://github.com/phelber/EuroSAT\">here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b589a",
   "metadata": {},
   "source": [
    "### EuroSAT satellite dataset contains images from 10 different classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a8cc0f",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Annual Crop</li>\n",
    "<li>Forest</li>\n",
    "<li>Herbaceous Vegetation</li>\n",
    "<li>Highway</li>\n",
    "<li>Industrial</li>\n",
    "<li>Pasture</li>\n",
    "<li>Permanent Crop</li>\n",
    "<li>Residential</li>\n",
    "<li>River</li>\n",
    "<li>SeaLake</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2f16a7",
   "metadata": {},
   "source": [
    "### 13 Spectral bands of a highway image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19cd416",
   "metadata": {},
   "source": [
    "<img src=\"sample-figure/euro-highway.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06fafbb",
   "metadata": {},
   "source": [
    "### 13 Spectral bands of an industry image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc641b6b",
   "metadata": {},
   "source": [
    "<img src=\"sample-figure/euro-industry.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9691d766",
   "metadata": {},
   "source": [
    "### Import Modules and Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8235ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from geotorchai.models.raster import DeepSatV2\n",
    "from geotorchai.datasets.raster import EuroSAT\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f16ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define parameters\n",
    "epoch_nums = 100\n",
    "learning_rate = 0.0002\n",
    "batch_size = 16\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed = int(time.time())\n",
    "params = {'batch_size': batch_size, 'shuffle': False}\n",
    "\n",
    "## make sure that PATH_TO_DATASET exists in the running directory\n",
    "PATH_TO_DATASET = \"data/eurosat\"\n",
    "MODEL_SAVE_PATH = \"model-deepsatv2\"\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97671b2b",
   "metadata": {},
   "source": [
    "### Load Data and Add Normalization Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c364e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data and calculate mean and std to perform normalization transform\n",
    "## Set download=True if dataset is not available in the given path\n",
    "fullData = EuroSAT(root = PATH_TO_DATASET, download=False)\n",
    "\n",
    "full_loader = DataLoader(fullData, batch_size= batch_size)\n",
    "channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "for i, sample in enumerate(full_loader):\n",
    "    data_temp, _ = sample\n",
    "    channels_sum += torch.mean(data_temp, dim=[0, 2, 3])\n",
    "    channels_squared_sum += torch.mean(data_temp**2, dim=[0, 2, 3])\n",
    "    num_batches += 1\n",
    "\n",
    "mean = channels_sum / num_batches\n",
    "std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca9ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the transform operation\n",
    "sat_transform = transforms.Normalize(mean, std)\n",
    "## Load data with desired transformation and additional handcrafted features enabled\n",
    "fullData = EuroSAT(root = PATH_TO_DATASET, include_additional_features = True, transform = sat_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04248edf",
   "metadata": {},
   "source": [
    "### Get All Class Names and Corresponding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d70271",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find all class names and corresponding labels\n",
    "print(fullData.get_class_labels())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356b1546",
   "metadata": {},
   "source": [
    "### Display Spectral Bands of the First Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display various bands from an input image\n",
    "input_data, label, features = fullData[1]\n",
    "f, ((ax1, ax2, ax3, ax4, ax5, ax6, ax7), (ax8, ax9, ax10, ax11, ax12, ax13, ax14)) = plt.subplots(2, 7, figsize=(15,5))\n",
    "ax14.axis('off')\n",
    "        \n",
    "ax1.set_title('Band-1')\n",
    "ax1.imshow(input_data[0])\n",
    "\n",
    "ax2.set_title('Band-2')\n",
    "ax2.imshow(input_data[1])\n",
    "\n",
    "ax3.set_title('Band-3')\n",
    "ax3.imshow(input_data[2])\n",
    "\n",
    "ax4.set_title('Band-4')\n",
    "ax4.imshow(input_data[3])\n",
    "\n",
    "ax5.set_title('Band-5')\n",
    "ax5.imshow(input_data[4])\n",
    "\n",
    "ax6.set_title('Band-6')\n",
    "ax6.imshow(input_data[5])\n",
    "\n",
    "ax7.set_title('Band-7')\n",
    "ax7.imshow(input_data[6])\n",
    "\n",
    "ax8.set_title('Band-8')\n",
    "ax8.imshow(input_data[7])\n",
    "\n",
    "ax9.set_title('Band-9')\n",
    "ax9.imshow(input_data[8])\n",
    "\n",
    "ax10.set_title('Band-10')\n",
    "ax10.imshow(input_data[9])\n",
    "\n",
    "ax11.set_title('Band-11')\n",
    "ax11.imshow(input_data[10])\n",
    "\n",
    "ax12.set_title('Band-12')\n",
    "ax12.imshow(input_data[11])\n",
    "\n",
    "ax13.set_title('Band-13')\n",
    "ax13.imshow(input_data[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93aa697",
   "metadata": {},
   "source": [
    "### Split Dataset into Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c32a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize training and validation indices to split the dataset\n",
    "dataset_size = len(fullData)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1368c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define training and validation data sampler\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "## Define training and validation data loader\n",
    "train_loader = DataLoader(fullData, **params, sampler=train_sampler)\n",
    "val_loader = DataLoader(fullData, **params, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba050da6",
   "metadata": {},
   "source": [
    "### Initialize Model and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3280cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set device to CPU or GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "## Define Model\n",
    "model = DeepSatV2(13, 64, 64, 10, len(fullData.ADDITIONAL_FEATURES))\n",
    "## Define hyper-parameters\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.to(device)\n",
    "loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2b3617",
   "metadata": {},
   "source": [
    "### Method for Returning Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f095c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Before starting training, define a method to calculate validation accuracy\n",
    "def get_validation_accuracy(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_sample = 0\n",
    "    correct = 0\n",
    "    for i, sample in enumerate(data_loader):\n",
    "        inputs, labels, features = sample\n",
    "        inputs = inputs.to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs, features)\n",
    "        total_sample += len(labels)\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total_sample\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e13af8",
   "metadata": {},
   "source": [
    "### Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d128caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform training and validation\n",
    "max_val_accuracy = None\n",
    "for e in range(epoch_nums):\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        inputs, labels, features = sample\n",
    "        inputs = inputs.to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs, features)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Training Loss: {:.4f}'.format(e + 1, epoch_nums, loss.item()))\n",
    "\n",
    "    ## Perform model validation after finishing each epoch training\n",
    "    val_accuracy = get_validation_accuracy(model, val_loader, device)\n",
    "    print(\"Validation Accuracy: \", val_accuracy, \"%\")\n",
    "\n",
    "    if max_val_accuracy == None or val_accuracy > max_val_accuracy:\n",
    "        max_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print('Best model saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
